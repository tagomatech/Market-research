{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Argus‑style Possibility Curves for MATIF Rapeseed\n",
        "\n",
        "**In‑sample exploration notebook** – we build and evaluate a 4‑parameter skew‑t model that forecasts the *full probability distribution* of the front‑month MATIF rapeseed future.\n",
        "\n",
        "### Sections\n",
        "1. Conceptual primer: APCs and the skew‑t distribution  \n",
        "2. Data preparation  \n",
        "3. Model definition (μ, σ, ν, τ)  \n",
        "4. Training loop (negative log‑likelihood)  \n",
        "5. Diagnostics: loss, quantile fan, PIT  \n",
        "6. Next steps\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generalised Distribution & Link–Function Architecture\n",
        "\n",
        "1. **Distribution**  \n",
        "\\[\\displaystyle\n",
        "  Y_{\\,t}^{\\text{indep.}} \\;\\sim\\; \\mathcal D\\!\\bigl(\\mu,\\;\\sigma,\\;\\nu,\\;\\tau\\bigr)\n",
        "\\]\n",
        "\n",
        "2. **Distribution parameters** — each obtained via a dedicated *link function* $g_i(\\cdot)$:\n",
        "\n",
        "\\[\\begin{aligned}\n",
        "\\eta_{1} &= g_{1}\\!\\bigl(\\mu\\bigr)  &&=\\; \\text{Fundamentals / Flows / Financials **or** forward‑curve levels} \\\\\n",
        "\\eta_{2} &= g_{2}\\!\\bigl(\\sigma\\bigr) &&=\\; \\text{Degree of uncertainty driven by Fundamentals / Flows / Financials} \\\\\n",
        "\\eta_{3} &= g_{3}\\!\\bigl(\\nu\\bigr)   &&=\\; \\text{Balance of risk (up‑ vs. down‑side) driven by Fundamentals / Flows / Financials} \\\\\n",
        "\\eta_{4} &= g_{4}\\!\\bigl(\\tau\\bigr)  &&=\\; \\text{Tail‑thickness (kurtosis) likewise driven by Fundamentals / Flows / Financials}\n",
        "\\end{aligned}\\]\n",
        "\n",
        "3. **Link‑function layer** — maps the chosen driver universe into the four distribution parameters, enabling separate functional forms for each moment of the predictive distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1 Conceptual primer\n",
        "\n",
        "**Possibility Curve (APC)**: a daily cumulative distribution function $F_{t+1}(x)$ giving the probability that tomorrow’s price ≤ $x$.\n",
        "\n",
        "We model\n",
        "$$P_{t+1} \\sim \\text{Skew}\\,t\\big(\\mu_t,\\,\\sigma_t,\\,\\nu_t,\\,\\tau_t\\big)$$\n",
        "where\n",
        "* $\\mu$ location (expected level)  \n",
        "* $\\sigma$ scale (volatility)  \n",
        "* $\\nu$ skewness (asymmetry)  \n",
        "* $\\tau$ tail‑weight (kurtosis).\n",
        "\n",
        "We implement a **SinhArcsinh‑transformed Student‑$t$** (Fernández & Steel) for analytic CDF/quantile evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tfd, tfb = tfp.distributions, tfp.bijectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2 Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Start of Added Code for Data Generation ---\n",
        "# This section generates dummy data for df_4_params to make the notebook runnable.\n",
        "# In a real scenario, you would load your actual MATIF rapeseed data here.\n",
        "\n",
        "np.random.seed(42) # for reproducibility\n",
        "n_samples = 1000\n",
        "\n",
        "# Generate synthetic 'close_rolled' data (e.g., a random walk)\n",
        "initial_price = 400.0\n",
        "price_changes = np.random.normal(0, 5, n_samples).cumsum()\n",
        "close_rolled = initial_price + price_changes\n",
        "\n",
        "# Generate synthetic features\n",
        "sma_20 = close_rolled * (1 + np.random.normal(0, 0.01, n_samples))\n",
        "sma_50 = close_rolled * (1 + np.random.normal(0, 0.02, n_samples))\n",
        "rsi_14 = np.random.uniform(30, 70, n_samples)\n",
        "atr_14 = np.random.uniform(5, 20, n_samples)\n",
        "bb_pct = np.random.uniform(0.1, 0.9, n_samples)\n",
        "z_score = np.random.normal(0, 1, n_samples)\n",
        "\n",
        "# Generate a date range\n",
        "dates = pd.date_range(start='2020-01-01', periods=n_samples, freq='D')\n",
        "\n",
        "# Create the DataFrame\n",
        "df_4_params = pd.DataFrame({\n",
        "    \"date\": dates,\n",
        "    \"close_rolled\": close_rolled,\n",
        "    \"sma_20\": sma_20,\n",
        "    \"sma_50\": sma_50,\n",
        "    \"rsi_14\": rsi_14,\n",
        "    \"atr_14\": atr_14,\n",
        "    \"bb_pct\": bb_pct,\n",
        "    \"z_score\": z_score\n",
        "})\n",
        "\n",
        "print(\"Dummy df_4_params created with shape:\", df_4_params.shape)\n",
        "print(df_4_params.head())\n",
        "\n",
        "# --- End of Added Code for Data Generation ---\n",
        "\n",
        "# target and features\n",
        "y_raw = df_4_params[\"close_rolled\"].astype(\"float32\").to_numpy()\n",
        "X_raw = df_4_params[[\"sma_20\",\"sma_50\",\"rsi_14\",\"atr_14\",\"bb_pct\",\"z_score\"]].astype(\"float32\").to_numpy()\n",
        "\n",
        "# standardise target\n",
        "y_mean, y_std = y_raw.mean(), y_raw.std()\n",
        "y_z = ((y_raw - y_mean) / y_std).reshape(-1,1)\n",
        "\n",
        "# normalise inputs with a Keras layer so scaling is saved in the model graph\n",
        "norm = tf.keras.layers.Normalization(); norm.adapt(X_raw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3 Skew‑t network\n",
        "* log‑σ and log‑τ ensure positivity  \n",
        "* tanh·5 caps $|\\nu|$ for numerical safety"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class APCSkewT(tf.keras.Model):\n",
        "    def __init__(self, hidden=32):\n",
        "        super().__init__()\n",
        "        # The normalization layer is passed from the outside, adapted to X_raw\n",
        "        self.norm = norm \n",
        "        self.f = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(hidden, activation=\"relu\"),\n",
        "            tf.keras.layers.Dense(hidden, activation=\"relu\")\n",
        "        ])\n",
        "        # Output layers for the four parameters\n",
        "        self.mu = tf.keras.layers.Dense(1, name='mu_output')\n",
        "        # log_s for scale (sigma), ensuring positivity with tf.exp\n",
        "        self.log_s = tf.keras.layers.Dense(1, bias_initializer=tf.constant_initializer(np.log(1.)), name='log_sigma_output')\n",
        "        # skew_h for skewness, capped by 5.*tf.tanh\n",
        "        self.skew_h = tf.keras.layers.Dense(1, name='skew_output')\n",
        "        # log_t for tailweight (tau), ensuring positivity with tf.exp\n",
        "        self.log_t = tf.keras.layers.Dense(1, bias_initializer=tf.constant_initializer(np.log(1.)), name='log_tau_output')\n",
        "\n",
        "    def call(self, x):\n",
        "        # Apply normalization to input features\n",
        "        x = self.norm(x)\n",
        "        # Pass through the shared feature extraction layers\n",
        "        h = self.f(x)\n",
        "        # Compute and return the four distribution parameters\n",
        "        return (\n",
        "            self.mu(h),\n",
        "            tf.exp(self.log_s(h)), # sigma must be positive\n",
        "            5. * tf.tanh(self.skew_h(h)), # skewness capped between -5 and 5\n",
        "            tf.exp(self.log_t(h)) # tailweight (tau) must be positive\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def skew_t(mu, sigma, skew, tail):\n",
        "    # Define the base distribution, a standard StudentT\n",
        "    # df=3. is a common choice for heavy-tailed distributions\n",
        "    base = tfd.StudentT(df=3., loc=0., scale=1.)\n",
        "    \n",
        "    # Apply transformations using bijectors:\n",
        "    # 1. SinhArcsinh: introduces skewness and tailweight\n",
        "    # 2. Scale: adjusts the spread (sigma)\n",
        "    # 3. Shift: adjusts the location (mu)\n",
        "    return tfd.TransformedDistribution(base, tfb.Chain([\n",
        "        tfb.Shift(mu),\n",
        "        tfb.Scale(sigma),\n",
        "        tfb.SinhArcsinh(skewness=skew, tailweight=tail)\n",
        "    ]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4 Training (negative log‑likelihood)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a TensorFlow Dataset for efficient batching and shuffling\n",
        "ds = tf.data.Dataset.from_tensor_slices((X_raw, y_z)).shuffle(500).batch(64)\n",
        "\n",
        "# Initialize the model and optimizer\n",
        "model = APCSkewT()\n",
        "opt = tf.keras.optimizers.Adam(1e-3)\n",
        "\n",
        "loss_log = []\n",
        "\n",
        "@tf.function # Decorator to compile the function into a TensorFlow graph for performance\n",
        "def step(bx, by):\n",
        "    with tf.GradientTape() as t:\n",
        "        # Get the predicted distribution parameters from the model\n",
        "        mu, s, k, tau = model(bx)\n",
        "        # Create the skew-t distribution\n",
        "        distribution = skew_t(mu, s, k, tau)\n",
        "        # Calculate the negative log-likelihood (NLL)\n",
        "        # tf.reduce_mean averages the NLL across the batch\n",
        "        loss = -tf.reduce_mean(distribution.log_prob(by))\n",
        "    \n",
        "    # Compute gradients and apply gradient clipping for stability\n",
        "    g, _ = tf.clip_by_global_norm(t.gradient(loss, model.trainable_variables), 2.)\n",
        "    # Apply gradients to update model weights\n",
        "    opt.apply_gradients(zip(g, model.trainable_variables))\n",
        "    return loss\n",
        "\n",
        "# Training loop\n",
        "for ep in range(30):\n",
        "    # Compute average loss for the current epoch\n",
        "    ll = np.mean([step(bx, by).numpy() for bx, by in ds])\n",
        "    loss_log.append(ll)\n",
        "    print(f\"epoch {ep+1:02d}: NLL {ll:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(loss_log, marker='o', linestyle='-', color='skyblue')\n",
        "plt.title(\"Training NLL Over Epochs\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"-log Likelihood\")\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5 Diagnostics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the predicted parameters for the entire dataset\n",
        "mu, s, k, tau = model(X_raw)\n",
        "# Create the distribution object\n",
        "dist = skew_t(mu, s, k, tau)\n",
        "\n",
        "# Calculate quantiles (10th, 25th, 50th, 75th, 90th percentile)\n",
        "# Quantiles are calculated in the standardized space and then transformed back to original scale\n",
        "q = tf.stack([dist.quantile(p) for p in [0.1, 0.25, 0.5, 0.75, 0.9]], axis=-1) * y_std + y_mean\n",
        "\n",
        "plt.figure(figsize=(12, 6));\n",
        "plt.plot(df_4_params[\"date\"], y_raw, lw=1.5, label=\"Actual Price\", color='darkblue')\n",
        "\n",
        "# Plot each quantile\n",
        "quantile_labels = [\"P10\", \"P25\", \"P50 (Median)\", \"P75\", \"P90\"]\n",
        "colors = ['lightcoral', 'salmon', 'darkgreen', 'mediumseagreen', 'lightgreen']\n",
        "for i, label in enumerate(quantile_labels):\n",
        "    plt.plot(df_4_params[\"date\"], q[:, i], ls=\"--\", label=label, alpha=0.7, color=colors[i])\n",
        "\n",
        "plt.legend(loc='upper left')\n",
        "plt.title(\"In‑sample Quantile Fan for MATIF Rapeseed Prices\")\n",
        "plt.xlabel(\"Date\")\n",
        "plt.ylabel(\"Price\")\n",
        "plt.grid(True, linestyle=':', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate Probability Integral Transform (PIT) values\n",
        "# PIT values should be uniformly distributed if the model is well-calibrated\n",
        "pit = dist.cdf(y_z.squeeze()).numpy()\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.hist(pit, bins=20, edgecolor='k', density=True, color='teal', alpha=0.7)\n",
        "plt.title(\"PIT Histogram (Probability Integral Transform)\")\n",
        "plt.xlabel(\"PIT Value\")\n",
        "plt.ylabel(\"Density\")\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.axhline(y=1.0, color='red', linestyle=':', label='Uniform Density')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6 Next steps\n",
        "1. Walk‑forward (t → t+1) evaluation and coverage stats  \n",
        "2. Driver‑universe scans (technical vs fundamentals vs curve)  \n",
        "3. Hyper‑parameter grid: hidden units, learning rate, clip‑norm  \n",
        "4. Dash UI for interactive model selection and fan charts\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
