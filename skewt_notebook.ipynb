{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Argus‑style Possibility Curves for MATIF Rapeseed\n",
    "\n",
    "**In‑sample exploration notebook** – we build and evaluate a 4‑parameter skew‑t model that forecasts the *full probability distribution* of the front‑month MATIF rapeseed future.\n",
    "\n",
    "### Sections\n",
    "1. Conceptual primer: APCs and the skew‑t distribution  \n",
    "2. Data preparation  \n",
    "3. Model definition (μ, σ, ν, τ)  \n",
    "4. Training loop (negative log‑likelihood)  \n",
    "5. Diagnostics: loss, quantile fan, PIT  \n",
    "6. Next steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Conceptual primer\n",
    "\n",
    "**Possibility Curve (APC)**: a daily cumulative distribution function $F_{t+1}(x)$ giving the probability that tomorrow’s price ≤ $x$.\n",
    "\n",
    "We model\n",
    "$$P_{t+1} \\sim \\text{Skew}\\,t\\big(\\mu_t,\\,\\sigma_t,\\,\\nu_t,\\,\\tau_t\\big)$$\n",
    "where\n",
    "* $\\mu$ location (expected level)  \n",
    "* $\\sigma$ scale (volatility)  \n",
    "* $\\nu$ skewness (asymmetry)  \n",
    "* $\\tau$ tail‑weight (kurtosis).\n",
    "\n",
    "We implement a **SinhArcsinh‑transformed Student‑$t$** (Fernández & Steel) for analytic CDF/quantile evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tfd, tfb = tfp.distributions, tfp.bijectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target and features\n",
    "y_raw = df_4_params[\"close_rolled\"].astype(\"float32\").to_numpy()\n",
    "X_raw = df_4_params[[\"sma_20\",\"sma_50\",\"rsi_14\",\"atr_14\",\"bb_pct\",\"z_score\"]].astype(\"float32\").to_numpy()\n",
    "\n",
    "# standardise target\n",
    "y_mean, y_std = y_raw.mean(), y_raw.std()\n",
    "y_z = ((y_raw - y_mean) / y_std).reshape(-1,1)\n",
    "\n",
    "# normalise inputs with a Keras layer so scaling is saved in the model graph\n",
    "norm = tf.keras.layers.Normalization(); norm.adapt(X_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Skew‑t network\n",
    "* log‑σ and log‑τ ensure positivity  \n",
    "* tanh·5 caps $|\\nu|$ for numerical safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class APCSkewT(tf.keras.Model):\n",
    "    def __init__(self, hidden=32):\n",
    "        super().__init__()\n",
    "        self.norm = norm\n",
    "        self.f = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(hidden, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(hidden, activation=\"relu\")])\n",
    "        self.mu = tf.keras.layers.Dense(1)\n",
    "        self.log_s = tf.keras.layers.Dense(1, bias_initializer=tf.constant_initializer(np.log(1.)))\n",
    "        self.skew_h = tf.keras.layers.Dense(1)\n",
    "        self.log_t = tf.keras.layers.Dense(1, bias_initializer=tf.constant_initializer(np.log(1.)))\n",
    "    def call(self,x):\n",
    "        x = self.norm(x)\n",
    "        h = self.f(x)\n",
    "        return ( self.mu(h),\n",
    "                 tf.exp(self.log_s(h)),\n",
    "                 5.*tf.tanh(self.skew_h(h)),\n",
    "                 tf.exp(self.log_t(h)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skew_t(mu,sigma,skew,tail):\n",
    "    base = tfd.StudentT(df=3.,loc=0.,scale=1.)\n",
    "    return tfd.TransformedDistribution(base, tfb.Chain([\n",
    "        tfb.Shift(mu), tfb.Scale(sigma), tfb.SinhArcsinh(skewness=skew, tailweight=tail)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Training (negative log‑likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices((X_raw, y_z)).shuffle(500).batch(64)\n",
    "model = APCSkewT(); opt = tf.keras.optimizers.Adam(1e-3)\n",
    "loss_log = []\n",
    "@tf.function\n",
    "def step(bx,by):\n",
    "    with tf.GradientTape() as t:\n",
    "        mu,s,k,tau = model(bx)\n",
    "        loss = -tf.reduce_mean(skew_t(mu,s,k,tau).log_prob(by))\n",
    "    g,_ = tf.clip_by_global_norm(t.gradient(loss,model.trainable_variables),2.)\n",
    "    opt.apply_gradients(zip(g,model.trainable_variables)); return loss\n",
    "for ep in range(30):\n",
    "    ll = np.mean([step(bx,by).numpy() for bx,by in ds])\n",
    "    loss_log.append(ll); print(f\"epoch {ep+1:02d}: NLL {ll:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_log); plt.title(\"Training NLL\"); plt.xlabel(\"epoch\"); plt.ylabel(\"-log L\"); plt.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu,s,k,tau = model(X_raw)\n",
    "dist = skew_t(mu,s,k,tau)\n",
    "q = tf.stack([dist.quantile(p) for p in [0.1,0.25,0.5,0.75,0.9]],axis=-1)*y_std + y_mean\n",
    "plt.figure(figsize=(9,4));\n",
    "plt.plot(df_4_params[\"date\"], y_raw, lw=1, label=\"actual\")\n",
    "for i,l in enumerate([\"10\",\"25\",\"50\",\"75\",\"90\"]):\n",
    "    plt.plot(df_4_params[\"date\"], q[:,i], ls=\"--\", label=f\"P{l}\")\n",
    "plt.legend(); plt.title(\"In‑sample quantile fan\"); plt.grid(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pit = dist.cdf(y_z.squeeze()).numpy(); plt.hist(pit,bins=20,edgecolor='k'); plt.title(\"PIT histogram\"); plt.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Next steps\n",
    "1. Walk‑forward (t → t+1) evaluation and coverage stats  \n",
    "2. Driver‑universe scans (technical vs fundamentals vs curve)  \n",
    "3. Hyper‑parameter grid: hidden units, learning rate, clip‑norm  \n",
    "4. Dash UI for interactive model selection and fan charts\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
